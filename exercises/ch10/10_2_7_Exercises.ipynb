{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f2b62b-44f3-4a73-987c-f98bd3fbd016",
   "metadata": {},
   "source": [
    "# 1. Assume that we only want to use the input at time step $t'$ to predict the output at time step $t\\gt t'$. What are the best values for the reset and update gates for each time step?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf88dea-fcd7-4d2b-a9a0-f89d501a6ded",
   "metadata": {},
   "source": [
    "- rest gate value can be any value\n",
    "- update gate value = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc598722-0257-41e5-b40b-41075c3d3e1d",
   "metadata": {},
   "source": [
    "# 2. Adjust the hyperparameters and analyze their influence on running time, perplexity, and the output sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69537900-b85e-48ff-aeb2-e51c2b7fe5fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import warnings\n",
    "sys.path.append('/home/jovyan/work/d2l_solutions/notebooks/exercises/d2l_utils/')\n",
    "import d2l\n",
    "from torchsummary import summary\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "class GRU(d2l.RNN):\n",
    "    def __init__(self, num_inputs, num_hiddens):\n",
    "        d2l.Module.__init__(self)\n",
    "        self.save_hyperparameters()\n",
    "        self.rnn = nn.GRU(num_inputs, num_hiddens)\n",
    "        \n",
    "def stat_val(model, data):\n",
    "    ppls = []\n",
    "    for batch in iter(data.get_dataloader(False)):\n",
    "        ppls.append(model.validation_step(batch, plot_flag=False).detach().numpy())\n",
    "    return np.exp(np.mean(ppls))\n",
    "\n",
    "def experient(data_class=d2l.TimeMachine, num_steps=32, num_hiddens=32, lr=1):\n",
    "    data = data_class(batch_size=1024, num_steps=num_steps)\n",
    "    gru = GRU(num_inputs=len(data.vocab), num_hiddens=num_hiddens)\n",
    "    model = d2l.RNNLM(gru, vocab_size=len(data.vocab), lr=lr)\n",
    "    trainer = d2l.Trainer(max_epochs=100, gradient_clip_val=1) #, num_gpus=1\n",
    "    trainer.fit(model, data)\n",
    "    return stat_val(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a34a1342-bf71-4a8b-94fb-c0088e8b1563",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m ppls \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m param_grid_obj:\n\u001b[0;32m----> 7\u001b[0m     ppl \u001b[38;5;241m=\u001b[39m \u001b[43mexperient\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     ppls\u001b[38;5;241m.\u001b[39mappend(ppl)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(params, ppl)\n",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m, in \u001b[0;36mexperient\u001b[0;34m(data_class, num_steps, num_hiddens, lr)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexperient\u001b[39m(data_class\u001b[38;5;241m=\u001b[39md2l\u001b[38;5;241m.\u001b[39mTimeMachine, num_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, num_hiddens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     24\u001b[0m     data \u001b[38;5;241m=\u001b[39m data_class(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, num_steps\u001b[38;5;241m=\u001b[39mnum_steps)\n\u001b[0;32m---> 25\u001b[0m     gru \u001b[38;5;241m=\u001b[39m \u001b[43mGRU\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hiddens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_hiddens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     model \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mRNNLM(gru, vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mvocab), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m     27\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, gradient_clip_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#, num_gpus=1\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m, in \u001b[0;36mGRU.__init__\u001b[0;34m(self, num_inputs, num_hiddens)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_inputs, num_hiddens):\n\u001b[0;32m---> 13\u001b[0m     \u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_hyperparameters()\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mGRU(num_inputs, num_hiddens)\n",
      "File \u001b[0;32m~/work/d2l_solutions/notebooks/exercises/d2l_utils/d2l.py:121\u001b[0m, in \u001b[0;36mModule.__init__\u001b[0;34m(self, plot_train_per_epoch, plot_valid_per_epoch)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, plot_train_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, plot_valid_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_hyperparameters()\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboard \u001b[38;5;241m=\u001b[39m ProgressBoard()\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "param_grid = {'num_steps':[8, 16, 32, 64, 128],\n",
    "              'num_hiddens':[8, 16, 32, 64, 128],\n",
    "              'lr':[0.01,0.1,1,10]}\n",
    "param_grid_obj = ParameterGrid(param_grid)\n",
    "ppls = []\n",
    "for params in param_grid_obj:\n",
    "    ppl = experient(**params)\n",
    "    ppls.append(ppl)\n",
    "    print(params, ppl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba93657-7f18-4a89-b247-9aee8ce115dc",
   "metadata": {},
   "source": [
    "# 3. Compare runtime, perplexity, and the output strings for rnn.RNN and rnn.GRU implementations with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cd6b6a-e9ff-4e38-b177-96ea921047e6",
   "metadata": {},
   "source": [
    "# 4. What happens if you implement only parts of a GRU, e.g., with only a reset gate or only an update gate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178dc3a-9d70-4516-9199-d98d5cc42caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetGRUScratch(d2l.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        init_weight = lambda *shape: nn.Parameter(torch.randn(*shape) * sigma)\n",
    "        triple = lambda: (init_weight(num_inputs, num_hiddens),\n",
    "                          init_weight(num_hiddens, num_hiddens),\n",
    "                          nn.Parameter(torch.zeros(num_hiddens)))\n",
    "        # self.W_xz, self.W_hz, self.b_z = triple()  # Update gate\n",
    "        self.W_xr, self.W_hr, self.b_r = triple()  # Reset gate\n",
    "        self.W_xh, self.W_hh, self.b_h = triple()  # Candidate hidden state\n",
    "        \n",
    "    def forward(self, inputs, H=None):\n",
    "        if H is None:\n",
    "            # Initial state with shape: (batch_size, num_hiddens)\n",
    "            H = torch.zeros((inputs.shape[1], self.num_hiddens),\n",
    "                          device=inputs.device)\n",
    "        outputs = []\n",
    "        for X in inputs:\n",
    "            # Z = torch.sigmoid(torch.matmul(X, self.W_xz) +\n",
    "            #                 torch.matmul(H, self.W_hz) + self.b_z)\n",
    "            R = torch.sigmoid(torch.matmul(X, self.W_xr) +\n",
    "                            torch.matmul(H, self.W_hr) + self.b_r)\n",
    "            H_tilde = torch.tanh(torch.matmul(X, self.W_xh) +\n",
    "                               torch.matmul(R * H, self.W_hh) + self.b_h)\n",
    "            H = Z * H + (1 - Z) * H_tilde\n",
    "            H = H_tilde\n",
    "            outputs.append(H)\n",
    "        return outputs, H\n",
    "    \n",
    "class UpdateGRUScratch(d2l.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        init_weight = lambda *shape: nn.Parameter(torch.randn(*shape) * sigma)\n",
    "        triple = lambda: (init_weight(num_inputs, num_hiddens),\n",
    "                          init_weight(num_hiddens, num_hiddens),\n",
    "                          nn.Parameter(torch.zeros(num_hiddens)))\n",
    "        self.W_xz, self.W_hz, self.b_z = triple()  # Update gate\n",
    "        # self.W_xr, self.W_hr, self.b_r = triple()  # Reset gate\n",
    "        self.W_xh, self.W_hh, self.b_h = triple()  # Candidate hidden state\n",
    "        \n",
    "    def forward(self, inputs, H=None):\n",
    "        if H is None:\n",
    "            # Initial state with shape: (batch_size, num_hiddens)\n",
    "            H = torch.zeros((inputs.shape[1], self.num_hiddens),\n",
    "                          device=inputs.device)\n",
    "        outputs = []\n",
    "        for X in inputs:\n",
    "            Z = torch.sigmoid(torch.matmul(X, self.W_xz) +\n",
    "                            torch.matmul(H, self.W_hz) + self.b_z)\n",
    "            # R = torch.sigmoid(torch.matmul(X, self.W_xr) +\n",
    "                            # torch.matmul(H, self.W_hr) + self.b_r)\n",
    "            H_tilde = torch.tanh(torch.matmul(X, self.W_xh) +\n",
    "                               torch.matmul(H, self.W_hh) + self.b_h)\n",
    "            H = Z * H + (1 - Z) * H_tilde\n",
    "            H = H_tilde\n",
    "            outputs.append(H)\n",
    "        return outputs, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81661187-9fcb-43c2-8fbc-4ce720d18989",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = d2l.TimeMachine(batch_size=1024, num_steps=32)\n",
    "gru = GRUScratch(num_inputs=len(data.vocab), num_hiddens=32)\n",
    "model = d2l.RNNLMScratch(gru, vocab_size=len(data.vocab), lr=4)\n",
    "trainer = d2l.Trainer(max_epochs=50, gradient_clip_val=1, num_gpus=1)\n",
    "trainer.fit(model, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l]",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
