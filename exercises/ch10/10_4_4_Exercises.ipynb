{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58c8d368-ba90-48df-8025-72393efc74e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. If the different directions use a different number of hidden units, how will the shape of $H_t$ change?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41779fd3-5f17-4ba8-93de-2f11fc355ca1",
   "metadata": {},
   "source": [
    "$H_t.shape[-1] = \\overrightarrow{H_t}.shape[-1] + \\overleftarrow{H_t}.shape[-1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22e3bde3-8077-4bb3-a705-279aade7a4ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import warnings\n",
    "sys.path.append('/home/jovyan/work/d2l_solutions/notebooks/exercises/d2l_utils/')\n",
    "import d2l\n",
    "from torchsummary import summary\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "class BiRNNScratch(d2l.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.f_rnn = d2l.RNNScratch(num_inputs, num_hiddens[0], sigma)\n",
    "        self.b_rnn = d2l.RNNScratch(num_inputs, num_hiddens[1], sigma)\n",
    "        self.num_hiddens = sum(num_hiddens)  # The output dimension will be doubled\n",
    "        \n",
    "    def forward(self, inputs, Hs=None):\n",
    "        f_H, b_H = Hs if Hs is not None else (None, None)\n",
    "        f_outputs, f_H = self.f_rnn(inputs, f_H)\n",
    "        b_outputs, b_H = self.b_rnn(reversed(inputs), b_H)\n",
    "        outputs = [torch.cat((f, b), -1) for f, b in zip(\n",
    "            f_outputs, reversed(b_outputs))]\n",
    "        return outputs, (f_H, b_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69b2eb54-e50e-49e8-819f-f15b990c4df3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'd2l' has no attribute 'RNNScratch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bi_rnn \u001b[38;5;241m=\u001b[39m \u001b[43mBiRNNScratch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hiddens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      3\u001b[0m outputs \u001b[38;5;241m=\u001b[39m BiRNNScratch(X)\n",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m, in \u001b[0;36mBiRNNScratch.__init__\u001b[0;34m(self, num_inputs, num_hiddens, sigma)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_hyperparameters()\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_rnn \u001b[38;5;241m=\u001b[39m \u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRNNScratch\u001b[49m(num_inputs, num_hiddens[\u001b[38;5;241m0\u001b[39m], sigma)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_rnn \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mRNNScratch(num_inputs, num_hiddens[\u001b[38;5;241m1\u001b[39m], sigma)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_hiddens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(num_hiddens)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'd2l' has no attribute 'RNNScratch'"
     ]
    }
   ],
   "source": [
    "bi_rnn = BiRNNScratch(num_inputs=4, num_hiddens=[8,16])\n",
    "X = torch.randn(4)\n",
    "outputs = BiRNNScratch(X)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025d46ab-5048-4795-b8f9-d7fdcde83935",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Design a bidirectional RNN with multiple hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe2147b-6bf3-4d56-801c-0dea21e48e23",
   "metadata": {},
   "source": [
    "# 3. Polysemy is common in natural languages. For example, the word “bank” has different meanings in contexts “i went to the bank to deposit cash” and “i went to the bank to sit down”. How can we design a neural network model such that given a context sequence and a word, a vector representation of the word in the correct context will be returned? What type of neural architectures is preferred for handling polysemy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e51e23-5a7c-4d55-8e7e-b351b663cbcc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l]",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
