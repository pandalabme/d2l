{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af830d32-dbc2-40a6-818a-848e2cb02e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to markdown 9_7_4_Exercises.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "895b7391-a96a-4324-a177-8efcc0d83ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import warnings\n",
    "sys.path.append('/home/jovyan/work/d2l_solutions/notebooks/exercises/d2l_utils/')\n",
    "import d2l\n",
    "from torchsummary import summary\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34f0bc1-db8b-4bc6-9d12-10cdf99b1e29",
   "metadata": {},
   "source": [
    "# 1. Adjust the hyperparameters and analyze their influence on running time, perplexity, and the output sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6d952-b52c-4868-86ca-2addaa088ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(d2l.RNN):\n",
    "    def __init__(self, num_inputs, num_hiddens):\n",
    "        d2l.Module.__init__(self)\n",
    "        self.save_hyperparameters()\n",
    "        self.rnn = nn.LSTM(num_inputs, num_hiddens)\n",
    "\n",
    "    def forward(self, inputs, H_C=None):\n",
    "        return self.rnn(inputs, H_C)\n",
    "    \n",
    "def stat_val(model, data):\n",
    "    ppls = []\n",
    "    for batch in iter(data.get_dataloader(False)):\n",
    "        ppls.append(model.validation_step(batch, plot_flag=False).detach().numpy())\n",
    "    return np.exp(np.mean(ppls))\n",
    "\n",
    "def experient(data_class=d2l.TimeMachine, num_steps=32, num_hiddens=32, lr=1):\n",
    "    data = data_class(batch_size=1024, num_steps=num_steps)\n",
    "    lstm = LSTM(num_inputs=len(data.vocab), num_hiddens=num_hiddens)\n",
    "    model = d2l.RNNLM(lstm, vocab_size=len(data.vocab), lr=lr)\n",
    "    trainer = d2l.Trainer(max_epochs=100, gradient_clip_val=1) #, num_gpus=1\n",
    "    trainer.fit(model, data)\n",
    "    return stat_val(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ec74a9-c679-4e72-9d63-918027dc3658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {'num_steps':[8, 16, 32, 64, 128],\n",
    "              'num_hiddens':[8, 16, 32, 64, 128],\n",
    "              'lr':[0.01,0.1,1,10]}\n",
    "param_grid_obj = ParameterGrid(param_grid)\n",
    "ppls = []\n",
    "for params in param_grid_obj:\n",
    "    ppl = experient(**params)\n",
    "    ppls.append(ppl)\n",
    "    print(params, ppl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c590d3f1-db29-4206-9168-61f66be7193d",
   "metadata": {},
   "source": [
    "# 2. How would you need to change the model to generate proper words rather than just sequences of characters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b7fba-f8de-4349-a0a1-5f1ab8deef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordTimeMachine(d2l.TimeMachine): \n",
    "    def _tokenize(self, text):\n",
    "        return text.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91916317-4c1d-4a4e-a858-f53c68a1f008",
   "metadata": {},
   "source": [
    "# 3. Compare the computational cost for GRUs, LSTMs, and regular RNNs for a given hidden dimension. Pay special attention to the training and inference cost.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be93986b-717c-444b-8be5-35144da55c23",
   "metadata": {},
   "source": [
    "# 4. Since the candidate memory cell ensures that the value range is between -1 and 1 by using the tanh function, why does the hidden state need to use the tanh function again to ensure that the output value range is between -1 and 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67892146-f51e-485b-b067-6c81e8fec75c",
   "metadata": {},
   "source": [
    "# 5. Implement an LSTM model for time series prediction rather than character sequence prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8970bd-e48d-408b-9c3c-255247e69f03",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e33471ae-458b-426d-a1c6-a351394767bc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a83152a2-24f8-46a2-b067-7289f797d426",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28a2d2f2-d5eb-4bad-9524-6482a2a25970",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef80b856-f7fe-44fe-8bb3-2476d3c546a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9355160f-dcf3-4fe8-b16a-6acb22ca601a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "058c099f-c87e-4e77-95d0-0dedf10c05c6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e00ec5b-c724-45b8-afc9-99868eda9c2f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l]",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
