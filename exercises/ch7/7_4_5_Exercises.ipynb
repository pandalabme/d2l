{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae743df-6982-49bd-b689-1a552dc3aa84",
   "metadata": {},
   "source": [
    "# 1. Assume that we have two convolution kernels of size $k_1$ and $k_2$, respectively (with no nonlinearity in between)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f366a4f-2460-4f9a-8b0f-b780691dc716",
   "metadata": {},
   "source": [
    "## 1.1 Prove that the result of the operation can be expressed by a single convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e30cff2-7376-48b6-87c4-736ad99ec0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 9.327\n",
      "epoch 4, loss 0.143\n",
      "epoch 6, loss 0.002\n",
      "epoch 8, loss 0.000\n",
      "epoch 10, loss 0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7815,  0.2595,  0.7211],\n",
       "        [ 0.4847, -1.4443, -0.1710],\n",
       "        [ 0.4958,  1.8198,  0.0529]], requires_grad=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_2 = torch.normal(0, 1, (3, 3), requires_grad=True)\n",
    "train_Y = corr2d(corr2d(X,K),K)\n",
    "y_pred = corr2d(X,K_2)\n",
    "lr = 1e-3  # Learning rate\n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = corr2d(X,K_2)\n",
    "    l = (Y_hat - train_Y) ** 2\n",
    "    # print(l)\n",
    "    \n",
    "    l.sum().backward()\n",
    "    # print(K_2.grad)\n",
    "    # Update the kernel\n",
    "    K_2.data -= lr * K_2.grad\n",
    "    K_2.grad.zero_()\n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f'epoch {i + 1}, loss {l.sum():.3f}')\n",
    "    # print(1,K_2)\n",
    "K_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d383cbbe-4bda-4961-88a0-aab509f758fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2]) torch.Size([3, 3]) torch.Size([4, 4])\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "def corr2d(X,K):\n",
    "    h,w = K.shape\n",
    "    Y = torch.zeros(X.shape[0]-h+1, X.shape[1]-w+1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i+h, j:j+w]*K).sum()\n",
    "    return Y\n",
    "\n",
    "X = torch.randn(size=(8, 8))\n",
    "# K_1 = torch.tensor([[1,0],[0,1]])\n",
    "K_1 = torch.randn(2, 2)\n",
    "K_1_1 = torch.randn(3, 3)\n",
    "# print(K_1)\n",
    "# print(corr2d(corr2d(X,K_1),K_1))\n",
    "# K_2 = torch.tensor([[4/3,0,0],[0,4/3,0],[0,0,4/3]])\n",
    "K_2 = F.conv_transpose2d(K_1.reshape(1,1,K_1.shape[0],-1), K_1_1.reshape(1,1,K_1_1.shape[0],-1)).squeeze()\n",
    "print(K_1.shape,K_1_1.shape,K_2.shape)\n",
    "print((corr2d(X,K_2)-corr2d(corr2d(X,K_1),K_1_1)< 1e-6).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a25b9fd-613d-4f8b-a4fd-9931be10f7d7",
   "metadata": {},
   "source": [
    "## 1.2 What is the dimensionality of the equivalent single convolution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa82dde9-6d87-443f-b52d-1db5c81b2dbf",
   "metadata": {},
   "source": [
    "$(k_1.h+k_2.h-1,k_1.w+k_2.w-1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2de48e-1750-4c86-827e-4deb3316e0f7",
   "metadata": {},
   "source": [
    "## 1.3 Is the converse true, i.e., can you always decompose a convolution into two smaller ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0b59eb0-6874-4d48-9fed-69597519de9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-20.7627, -20.7627, -20.7627, -20.7627, -20.7627, -20.7627],\n",
       "        [-20.7627, -20.7627, -20.7627, -20.7627, -20.7627, -20.7627],\n",
       "        [-20.7627, -20.7627, -20.7627, -20.7627, -20.7627, -20.7627],\n",
       "        [-20.7627, -20.7627, -20.7627, -20.7627, -20.7627, -20.7627],\n",
       "        [-20.7627, -20.7627, -20.7627, -20.7627, -20.7627, -20.7627],\n",
       "        [-20.7627, -20.7627, -20.7627, -20.7627, -20.7627, -20.7627]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_2 = torch.randn(3,3)\n",
    "K_1 = torch.randn(2,2)\n",
    "K_1_1 = corr2d(K_2,K_1)\n",
    "corr2d(corr2d(X,K_1_1),K_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "15df57a0-ef6c-40d4-bb7c-37dcd42389b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-20.7627, -20.7627, -20.7627, -20.7627, -20.7627, -20.7627],\n",
       "        [-20.7627, -20.7627, -20.7627, -20.7627, -20.7627, -20.7627],\n",
       "        [-20.7627, -20.7627, -20.7627, -20.7627, -20.7627, -20.7627],\n",
       "        [-20.7627, -20.7627, -20.7627, -20.7627, -20.7627, -20.7627],\n",
       "        [-20.7627, -20.7627, -20.7627, -20.7627, -20.7627, -20.7627],\n",
       "        [-20.7627, -20.7627, -20.7627, -20.7627, -20.7627, -20.7627]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(corr2d(X,K_1),K_1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b07160f1-6d0c-402d-b09a-6fcfe6eb9df2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.5812, -4.5812, -4.5812, -4.5812, -4.5812, -4.5812],\n",
       "        [-4.5812, -4.5812, -4.5812, -4.5812, -4.5812, -4.5812],\n",
       "        [-4.5812, -4.5812, -4.5812, -4.5812, -4.5812, -4.5812],\n",
       "        [-4.5812, -4.5812, -4.5812, -4.5812, -4.5812, -4.5812],\n",
       "        [-4.5812, -4.5812, -4.5812, -4.5812, -4.5812, -4.5812],\n",
       "        [-4.5812, -4.5812, -4.5812, -4.5812, -4.5812, -4.5812]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X,K_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cacf9a-bbd4-4fe8-98b8-baa892061490",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c91f5e08-16e0-44cf-8698-9aa52304a44d",
   "metadata": {},
   "source": [
    "# 2. Assume an input of shape \n",
    " and a convolution kernel of shape \n",
    ", padding of \n",
    ", and stride of \n",
    ".\n",
    "\n",
    "What is the computational cost (multiplications and additions) for the forward propagation?\n",
    "\n",
    "What is the memory footprint?\n",
    "\n",
    "What is the memory footprint for the backward computation?\n",
    "\n",
    "What is the computational cost for the backpropagation?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ddf17d-8c32-4ce2-8648-4e64ec2579b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87ad4568-07b2-4277-ad91-d8d832333205",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9dfa648-f2a7-4d7b-b565-101a45f91f5e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d63f809-633e-49d0-a551-aa5ddde0621e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e083d8df-caac-4c07-a379-06b99f14ce5b",
   "metadata": {},
   "source": [
    "# 3. By what factor does the number of calculations increase if we double both the number of input channels \n",
    " and the number of output channels \n",
    "? What happens if we double the padding?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e764e97e-2e3f-4b4b-9d72-441da4edbc8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6814d6f2-9290-444a-8f9b-7e81c1c4623d",
   "metadata": {},
   "source": [
    "# 4. Are the variables Y1 and Y2 in the final example of this section exactly the same? Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0f7ff4-4d05-4633-b54b-65d88f6ce335",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65edd42f-5585-433a-ad87-9add4b92f0a3",
   "metadata": {},
   "source": [
    "# 5. Express convolutions as a matrix multiplication, even when the convolution window is not \n",
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe76a1da-cd33-4ba5-8fda-5c3f0166e65a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96ce088f-96a2-4b3f-b42e-2b5216cf4ccf",
   "metadata": {},
   "source": [
    "# 6. Your task is to implement fast convolutions with a \n",
    " kernel. One of the algorithm candidates is to scan horizontally across the source, reading a \n",
    "-wide strip and computing the \n",
    "-wide output strip one value at a time. The alternative is to read a \n",
    " wide strip and compute a \n",
    "-wide output strip. Why is the latter preferable? Is there a limit to how large you should choose \n",
    "?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159f56c6-69d5-43be-a08a-f55cb30771a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77d48365-902d-4097-ae91-4e95e41cb3ad",
   "metadata": {},
   "source": [
    "# 7. Assume that we have a \n",
    " matrix.\n",
    "\n",
    "How much faster is it to multiply with a block-diagonal matrix if the matrix is broken up into \n",
    " blocks?\n",
    "\n",
    "What is the downside of having \n",
    " blocks? How could you fix it, at least partly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ead54d3-44aa-4e85-8c56-1d52ff8d3934",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2da66acf-135b-44e4-84bf-023c4dad2d30",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a931bbda-d65a-4225-9944-06dd5c450767",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l]",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
