{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae743df-6982-49bd-b689-1a552dc3aa84",
   "metadata": {},
   "source": [
    "# 1. Assume that we have two convolution kernels of size $k_1$ and $k_2$, respectively (with no nonlinearity in between)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f366a4f-2460-4f9a-8b0f-b780691dc716",
   "metadata": {},
   "source": [
    "## 1.1 Prove that the result of the operation can be expressed by a single convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3203479c-2796-443b-9bc0-ac1f124d55a3",
   "metadata": {},
   "source": [
    "Let's assume we have two convolution kernels with sizes $k_1$ and $k_2$, and we perform the convolutions sequentially without any nonlinearity in between. The question is asking us to prove that the result of these two convolution operations can be expressed as a single convolution operation.\n",
    "\n",
    "To prove this, we need to show that the sequential convolutions can be combined into a single convolution operation with a single convolution kernel. To do this, let's consider the following steps:\n",
    "\n",
    "1. **Sequential Convolution**: First, we apply the convolution kernel $k_1$ to the input. This produces an intermediate feature map $F_1$.\n",
    "\n",
    "2. **Convolution of $F_1$ with $k_2$**: Instead of applying the second convolution kernel $k_2$ to the original input, we will apply it to the intermediate feature map $F_1$ obtained from the first convolution. This results in the final output feature map $O$ that we would have obtained by applying both convolution kernels sequentially.\n",
    "\n",
    "Mathematically, this can be expressed as follows:\n",
    "\n",
    "Let $I$ be the input tensor, $F_1$ be the intermediate feature map obtained from the convolution with $k_1$, and $O$ be the final output feature map obtained from the sequential convolutions with $k_1$ and $k_2$:\n",
    "\n",
    "$$ F_1 = I \\ast k_1 $$\n",
    "$$ O = F_1 \\ast k_2 $$\n",
    "\n",
    "Substituting the value of $F_1$ from the first equation into the second equation:\n",
    "\n",
    "$$ O = (I \\ast k_1) \\ast k_2 $$\n",
    "\n",
    "By associativity of convolution operations:\n",
    "\n",
    "$$ O = I \\ast (k_1 \\ast k_2) $$\n",
    "\n",
    "So, the result of applying the sequential convolutions $k_1$ and $k_2$ can be expressed as a single convolution with a kernel that is the convolution of $k_1$ and $k_2$, denoted as $k_1 \\ast k_2$.\n",
    "\n",
    "This proves that the result of applying two convolution kernels sequentially can be expressed as a single convolution with an appropriately calculated convolution kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d60660d-c666-4452-8f42-6779095003c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output feature map (Sequential convolutions):\n",
      " tensor([[[[ 48.,  16., -32.],\n",
      "          [ 24.,   0., -24.],\n",
      "          [-48., -16.,  32.]]]])\n",
      "Output feature map (Combined convolution):\n",
      " tensor([[[[-20.,  -8.,  20.],\n",
      "          [-24.,   0.,  24.],\n",
      "          [ 20.,   8., -20.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Create a sample input tensor\n",
    "input_tensor = torch.tensor([[[[1, 2, 3],\n",
    "                               [4, 5, 6],\n",
    "                               [7, 8, 9]]]], dtype=torch.float32)\n",
    "\n",
    "# Define two convolution kernels\n",
    "kernel1 = torch.tensor([[[[1, 0, -1],\n",
    "                          [2, 0, -2],\n",
    "                          [1, 0, -1]]]], dtype=torch.float32)\n",
    "\n",
    "kernel2 = torch.tensor([[[[1, 2, 1],\n",
    "                          [0, 0, 0],\n",
    "                          [-1, -2, -1]]]], dtype=torch.float32)\n",
    "\n",
    "# Apply the convolutions sequentially\n",
    "intermediate_feature_map = F.conv2d(input_tensor, kernel1, stride=1, padding=1)\n",
    "output_feature_map = F.conv2d(intermediate_feature_map, kernel2, stride=1, padding=1)\n",
    "\n",
    "# Apply the combined convolution\n",
    "combined_kernel = F.conv2d(kernel1, kernel2, stride=1, padding=1)\n",
    "single_conv_output = F.conv2d(input_tensor, combined_kernel, stride=1, padding=1)\n",
    "\n",
    "# Compare the results\n",
    "print(\"Output feature map (Sequential convolutions):\\n\", output_feature_map)\n",
    "print(\"Output feature map (Combined convolution):\\n\", single_conv_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d383cbbe-4bda-4961-88a0-aab509f758fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4., 4.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "def corr2d(X,K):\n",
    "    h,w = K.shape\n",
    "    Y = torch.zeros(X.shape[0]-h+1, X.shape[1]-w+1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i+h, j:j+w]*K).sum()\n",
    "    return Y\n",
    "\n",
    "X = torch.ones(size=(8, 8))\n",
    "K = torch.tensor([[1,0],[0,1]])\n",
    "print(corr2d(corr2d(X,K),K))\n",
    "K_2 = torch.tensor([[4/3,0,0],[0,4/3,0],[0,0,4/3]])\n",
    "(corr2d(X,K_2) == corr2d(corr2d(X,K),K)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e632775-eda9-40eb-b1f6-00f6c1c4d918",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1) indicates that batch size and the number of channels are both 1\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # Strip the first two dimensions: examples and channels\n",
    "    return Y.reshape(Y.shape[2:])\n",
    "\n",
    "# 1 row and column is padded on either side, so a total of 2 rows or columns\n",
    "# are added\n",
    "conv2d = nn.LazyConv2d(1, kernel_size=(3,3), padding=(1,1))\n",
    "X = torch.rand(size=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a25b9fd-613d-4f8b-a4fd-9931be10f7d7",
   "metadata": {},
   "source": [
    "## 1.2 What is the dimensionality of the equivalent single convolution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2de48e-1750-4c86-827e-4deb3316e0f7",
   "metadata": {},
   "source": [
    "## 1.3 Is the converse true, i.e., can you always decompose a convolution into two smaller ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91f5e08-16e0-44cf-8698-9aa52304a44d",
   "metadata": {},
   "source": [
    "# 2. Assume an input of shape \n",
    " and a convolution kernel of shape \n",
    ", padding of \n",
    ", and stride of \n",
    ".\n",
    "\n",
    "What is the computational cost (multiplications and additions) for the forward propagation?\n",
    "\n",
    "What is the memory footprint?\n",
    "\n",
    "What is the memory footprint for the backward computation?\n",
    "\n",
    "What is the computational cost for the backpropagation?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ddf17d-8c32-4ce2-8648-4e64ec2579b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87ad4568-07b2-4277-ad91-d8d832333205",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9dfa648-f2a7-4d7b-b565-101a45f91f5e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d63f809-633e-49d0-a551-aa5ddde0621e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e083d8df-caac-4c07-a379-06b99f14ce5b",
   "metadata": {},
   "source": [
    "# 3. By what factor does the number of calculations increase if we double both the number of input channels \n",
    " and the number of output channels \n",
    "? What happens if we double the padding?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e764e97e-2e3f-4b4b-9d72-441da4edbc8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6814d6f2-9290-444a-8f9b-7e81c1c4623d",
   "metadata": {},
   "source": [
    "# 4. Are the variables Y1 and Y2 in the final example of this section exactly the same? Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0f7ff4-4d05-4633-b54b-65d88f6ce335",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65edd42f-5585-433a-ad87-9add4b92f0a3",
   "metadata": {},
   "source": [
    "# 5. Express convolutions as a matrix multiplication, even when the convolution window is not \n",
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe76a1da-cd33-4ba5-8fda-5c3f0166e65a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96ce088f-96a2-4b3f-b42e-2b5216cf4ccf",
   "metadata": {},
   "source": [
    "# 6. Your task is to implement fast convolutions with a \n",
    " kernel. One of the algorithm candidates is to scan horizontally across the source, reading a \n",
    "-wide strip and computing the \n",
    "-wide output strip one value at a time. The alternative is to read a \n",
    " wide strip and compute a \n",
    "-wide output strip. Why is the latter preferable? Is there a limit to how large you should choose \n",
    "?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159f56c6-69d5-43be-a08a-f55cb30771a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77d48365-902d-4097-ae91-4e95e41cb3ad",
   "metadata": {},
   "source": [
    "# 7. Assume that we have a \n",
    " matrix.\n",
    "\n",
    "How much faster is it to multiply with a block-diagonal matrix if the matrix is broken up into \n",
    " blocks?\n",
    "\n",
    "What is the downside of having \n",
    " blocks? How could you fix it, at least partly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ead54d3-44aa-4e85-8c56-1d52ff8d3934",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2da66acf-135b-44e4-84bf-023c4dad2d30",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a931bbda-d65a-4225-9944-06dd5c450767",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l]",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
