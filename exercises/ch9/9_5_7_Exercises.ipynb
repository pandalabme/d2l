{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b3615d6-bbf4-4eff-a05d-a25c6af26eae",
   "metadata": {},
   "source": [
    "# 1. Does the implemented language model predict the next token based on all the past tokens up to the very first token in The Time Machine?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b8307-259d-4b16-b24a-daea4fb75f75",
   "metadata": {},
   "source": [
    "The prediction of the next token is influenced by a fixed-length context window, which is controled by the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f88eb3-4f7e-45ef-bec1-aeba1327eb90",
   "metadata": {},
   "source": [
    "# 2. Which hyperparameter controls the length of history used for prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e308b3d-a558-4b9c-9985-d9406be85bdc",
   "metadata": {},
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6731a230-f9f5-42b8-9c6b-1990b2bf67d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9867bde-4295-4db2-a6fd-75344ce3a513",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e894e79-13bc-4ac1-93aa-a3b0d02a27be",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7a55423-5e59-412c-b433-5c95a9746c8d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fb7a4a6-72c8-49bf-81cb-4f23f6ddb85f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72519807-8bc8-4ca8-aea8-2db6c3e12a83",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d329f049-89d0-40b3-a011-923be6d94372",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eec87cea-09d2-4df7-b0d5-6b7d522c5419",
   "metadata": {},
   "source": [
    "# 3. Show that one-hot encoding is equivalent to picking a different embedding for each object.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263dfb0e-e499-4dbd-b759-da0d7c831a27",
   "metadata": {},
   "source": [
    "# 4. Adjust the hyperparameters (e.g., number of epochs, number of hidden units, number of time steps in a minibatch, and learning rate) to improve the perplexity. How low can you go while sticking with this simple architecture?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4968fb-7a23-4282-8109-e9c84960ffc0",
   "metadata": {},
   "source": [
    "# 5. Replace one-hot encoding with learnable embeddings. Does this lead to better performance?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31d825a-eb6b-4f95-a831-0d29379c4202",
   "metadata": {},
   "source": [
    "# 6. Conduct an experiment to determine how well this language model trained on The Time Machine works on other books by H. G. Wells, e.g., The War of the Worlds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0ddbff-784f-4482-8653-2c8b6c6455f0",
   "metadata": {},
   "source": [
    "# 7. Conduct another experiment to evaluate the perplexity of this model on books written by other authors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e514e-0be7-4084-8c96-6a2907e3df31",
   "metadata": {},
   "source": [
    "# 8. Modify the prediction method so as to use sampling rather than picking the most likely next character.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1af15e-f2eb-4ef6-96b0-3c04f0371524",
   "metadata": {},
   "source": [
    "## 8.1 What happens?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23abb36-8118-48c5-b76f-aebaf25bc6f9",
   "metadata": {},
   "source": [
    "## 8.2 Bias the model towards more likely outputs, e.g., by sampling from \n",
    " for \n",
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7f801b-efb6-4cce-885a-97f4ba9ff574",
   "metadata": {},
   "source": [
    "# 9. Run the code in this section without clipping the gradient. What happens?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e793f2b7-6740-4d8d-88ee-3484ca6bb0ea",
   "metadata": {},
   "source": [
    "# 10. Replace the activation function used in this section with ReLU and repeat the experiments in this section. Do we still need gradient clipping? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c680c250-b12c-4ac7-ae00-864f6ceb7d51",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90cad5e3-c31b-479b-b0e0-4b2aec6163b5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82f68ce4-965d-464c-a269-845550e686de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "240a76b4-f884-4d62-8d7e-dadb5fd4e2c3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce901b79-eb27-47d4-a060-7d4b8cffa711",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a700b78c-a6ab-4ec6-b5c2-7c22bbda2d9d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "890aa6a0-78cb-466c-8ea2-725f3e111e6c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8177fc92-7828-4ef1-9f25-3204c131c92a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c130d0fc-f996-4002-b128-52353fd71511",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l]",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
