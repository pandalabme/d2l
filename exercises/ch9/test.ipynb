{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a415ad0f-ebe8-4650-9f2f-026118b2c1db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import warnings\n",
    "sys.path.append('/home/jovyan/work/d2l_solutions/notebooks/exercises/d2l_utils/')\n",
    "import d2l\n",
    "from torchsummary import summary\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class Data(d2l.DataModule):\n",
    "    def __init__(self, batch_size=16, T=1000, num_train=600, tau=4, randn=0.2):\n",
    "        self.save_hyperparameters()\n",
    "        self.time = torch.range(1, T, dtype=torch.float32)\n",
    "        self.x = torch.sin(0.01*self.time) + torch.randn(T)*randn\n",
    "        \n",
    "    def get_dataloader(self, train):\n",
    "        features = [self.x[i:self.T-self.tau+i] for i in range(self.tau)]\n",
    "        self.features = torch.stack(features, 1).unsqueeze(dim=-1).swapaxes(0, 1)\n",
    "        self.labels = self.x[self.tau:].reshape((-1, 1))\n",
    "        i = slice(0, self.num_train) if train else slice(self.num_train, None)\n",
    "        return self.get_tensorloader([self.features, self.labels], train, i)\n",
    "    \n",
    "class RNN(d2l.Module):  #@save\n",
    "    \"\"\"The RNN model implemented with high-level APIs.\"\"\"\n",
    "    def __init__(self, num_inputs, num_hiddens):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.rnn = nn.RNN(num_inputs, num_hiddens)\n",
    "\n",
    "    def forward(self, inputs, H=None):\n",
    "        return self.rnn(inputs, H)\n",
    "    \n",
    "class RNNAutoRegression(d2l.LinearRegression):  #@save\n",
    "    \"\"\"The RNN-based language model implemented with high-level APIs.\"\"\"\n",
    "    def init_params(self):\n",
    "        self.linear = nn.LazyLinear(1)\n",
    "\n",
    "    # def output_layer(self, hiddens):\n",
    "    #     return self.linear(hiddens).swapaxes(0, 1)\n",
    "    \n",
    "    def __init__(self, rnn,lr=0.01, tau=4, plot_flag=True, emb_len=8):\n",
    "        super().__init__(lr=lr)\n",
    "        self.save_hyperparameters()\n",
    "        self.init_params()   \n",
    "\n",
    "    def forward(self, X, state=None):\n",
    "        rnn_outputs, _ = self.rnn(X, state)\n",
    "        print(X.shape,rnn_outputs.shape)\n",
    "        return self.linear(rnn_outputs[-1])\n",
    "        # return rnn_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91d0782-04fe-46dc-b21a-7c3c2fdf3ef4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = d2l.TimeMachine(batch_size=1024, num_steps=32)\n",
    "# rnn = d2l.RNN(num_inputs=len(data.vocab), num_hiddens=32)\n",
    "# model = d2l.RNNLM(rnn, vocab_size=len(data.vocab), lr=1)\n",
    "# model.predict('it has', 20, data.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b82748fc-957c-41b6-9509-1a6157a271be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1, 8]), torch.Size([1, 1, 8]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = rnn(data.features[:,:1,:])\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0bd1619-6165-486d-889b-5ccff0bbfc1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Size mismatch between tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m RNNAutoRegression(rnn\u001b[38;5;241m=\u001b[39mrnn, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/d2l_solutions/notebooks/exercises/d2l_utils/d2l.py:220\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, data):\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_model(model)\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfigure_optimizers()\n",
      "File \u001b[0;32m~/work/d2l_solutions/notebooks/exercises/d2l_utils/d2l.py:209\u001b[0m, in \u001b[0;36mTrainer.prepare_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_data\u001b[39m(\u001b[38;5;28mself\u001b[39m,data):\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_dataloader \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mval_dataloader()\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader)\n",
      "File \u001b[0;32m~/work/d2l_solutions/notebooks/exercises/d2l_utils/d2l.py:126\u001b[0m, in \u001b[0;36mDataModule.train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_dataloader\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m, in \u001b[0;36mData.get_dataloader\u001b[0;34m(self, train)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtau:]\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     23\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train) \u001b[38;5;28;01mif\u001b[39;00m train \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tensorloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/d2l_solutions/notebooks/exercises/d2l_utils/d2l.py:134\u001b[0m, in \u001b[0;36mDataModule.get_tensorloader\u001b[0;34m(self, tensors, train, indices)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Defined in :numref:`sec_synthetic-regression-data`\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(a[indices] \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m tensors)\n\u001b[0;32m--> 134\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m    136\u001b[0m                                    shuffle\u001b[38;5;241m=\u001b[39mtrain)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataset.py:192\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(tensors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "\u001b[0;31mAssertionError\u001b[0m: Size mismatch between tensors"
     ]
    }
   ],
   "source": [
    "tau=4\n",
    "data = Data(tau=tau)\n",
    "rnn = RNN(num_inputs=1, num_hiddens=8)\n",
    "model = RNNAutoRegression(rnn=rnn, lr=0.01)\n",
    "trainer = d2l.Trainer(max_epochs=5)\n",
    "trainer.fit(model, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l]",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
