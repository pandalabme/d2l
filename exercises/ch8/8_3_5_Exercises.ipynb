{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91c1514c-8ab4-4f25-814f-fae34e461359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import warnings\n",
    "sys.path.append('/home/jovyan/work/d2l_solutions/notebooks/exercises/d2l_utils/')\n",
    "import d2l\n",
    "from torchsummary import summary\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def nin_block(out_channels, kernel_size, stride, padding, nums_conv1, conv1_size=1):\n",
    "    layers = [nn.LazyConv2d(out_channels, kernel_size=kernel_size, stride=stride, padding=padding),nn.ReLU()]\n",
    "    for i in range(nums_conv1):\n",
    "        layers.append(nn.LazyConv2d(out_channels, kernel_size=conv1_size))\n",
    "        layers.append(nn.ReLU())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class Nin(d2l.Classifier):\n",
    "    def __init__(self, arch, lr=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        layers = []\n",
    "        for i in range(len(arch)-1):\n",
    "            layers.append(nin_block(*arch[i]))\n",
    "            layers.append(nn.MaxPool2d(3, stride=2))\n",
    "        layers.append(nn.Dropout(0.5))\n",
    "        layers.append(nin_block(*arch[-1]))\n",
    "        layers.append(nn.AdaptiveAvgPool2d((1, 1)))\n",
    "        layers.append(nn.Flatten())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.net.apply(d2l.init_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f94a8fb-7eb0-4a5f-80f8-b9af28e03fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nin(\n",
       "  (net): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): LazyConv2d(0, 96, kernel_size=(11, 11), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): LazyConv2d(0, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): LazyConv2d(0, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): Sequential(\n",
       "      (0): LazyConv2d(0, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): ReLU()\n",
       "      (2): LazyConv2d(0, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): LazyConv2d(0, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): LazyConv2d(0, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): LazyConv2d(0, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): LazyConv2d(0, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Dropout(p=0.5, inplace=False)\n",
       "    (7): Sequential(\n",
       "      (0): LazyConv2d(0, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): LazyConv2d(0, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): LazyConv2d(0, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (9): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch = ((96,11,4,0,2),(256,5,1,2,2),(384,3,1,1,2),(10,3,1,1,2))\n",
    "model = Nin(arch)\n",
    "data = d2l.FashionMNIST(batch_size=128, resize=(28, 28))\n",
    "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
    "trainer.fit(model, data)\n",
    "X,y = next(iter(data.get_dataloader(False)))\n",
    "X = X.to('cuda')\n",
    "y = y.to('cuda')\n",
    "y_hat = model(X) \n",
    "print(f'acc: {model.accuracy(y_hat,y).item():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4989934d-2b05-406c-a62e-d90b5a09bd29",
   "metadata": {},
   "source": [
    "# 1. Why are there two $1\\times1$ convolutional layers per NiN block? Increase their number to three. Reduce their number to one. What changes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ffa8f3-8c08-4b4b-91cf-ac1cdf1e93ee",
   "metadata": {},
   "source": [
    "In Network in Network (NiN) architecture, $1\\times1$ convolutional layers are used to introduce additional non-linearity and increase the capacity of the network without introducing too many parameters. The inclusion of these $1\\times1$ convolutions has specific effects on the network's expressiveness and complexity:\n",
    "\n",
    "1. **Two $1\\times1$ Convolutional Layers per NiN Block**:\n",
    "   - When there are two $1\\times1$ convolutional layers per NiN block, it creates multiple pathways for feature transformation. Each $1\\times1$ convolution performs its own set of operations, allowing the network to capture complex relationships between features and enable better representation learning.\n",
    "   - Having two $1\\times1$ convolutions can increase the model's capacity and non-linearity, potentially leading to improved accuracy and more expressive features.\n",
    "\n",
    "2. **Three $1\\times1$ Convolutional Layers per NiN Block**:\n",
    "   - Increasing the number of $1\\times1$ convolutional layers further amplifies the network's capacity. Each additional convolutional layer introduces more non-linearity and the possibility of capturing more complex interactions between features.\n",
    "   - However, increasing the number of $1\\times1$ convolutions also increases the number of parameters and computations, potentially leading to overfitting and higher computational costs.\n",
    "\n",
    "3. **One $1\\times1$ Convolutional Layer per NiN Block**:\n",
    "   - Using only one $1\\times1$ convolutional layer reduces the complexity of each NiN block. It limits the capacity of the network to capture complex feature interactions, and may lead to underfitting if the dataset and task are complex.\n",
    "   - Reducing the number of $1\\times1$ convolutions also decreases the number of parameters and computations, which can be beneficial for faster training and reduced memory usage.\n",
    "\n",
    "Overall, the number of $1\\times1$ convolutional layers in NiN blocks impacts the network's capacity, complexity, and computational requirements. The optimal choice depends on factors such as the dataset's complexity, available computational resources, and desired trade-off between accuracy and efficiency. Experimentation and validation on a specific task are necessary to determine the most suitable configuration for the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3be56373-dbba-4733-8eda-53ae418d812b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arch = ((96,11,4,0,3),(256,5,1,2,3),(384,3,1,1,3),(10,3,1,1,3))\n",
    "model = Nin(arch)\n",
    "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
    "trainer.fit(model, data)\n",
    "X,y = next(iter(data.get_dataloader(False)))\n",
    "X = X.to('cuda')\n",
    "y = y.to('cuda')\n",
    "y_hat = model(X) \n",
    "print(f'acc: {model.accuracy(y_hat,y).item():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15157aa-285b-4048-bd03-40fc3d4b92a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = ((96,11,4,0,1),(256,5,1,2,1),(384,3,1,1,1),(10,3,1,1,1))\n",
    "model = Nin(arch)\n",
    "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
    "trainer.fit(model, data)\n",
    "X,y = next(iter(data.get_dataloader(False)))\n",
    "X = X.to('cuda')\n",
    "y = y.to('cuda')\n",
    "y_hat = model(X) \n",
    "print(f'acc: {model.accuracy(y_hat,y).item():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccad96b-760c-4e10-a20b-0ae800640c8b",
   "metadata": {},
   "source": [
    "# 2. What changes if you replace the $1\\times1$ convolutions by $3\\times3$ convolutions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04de0a08-6c85-4cf2-bdb9-2622b440365e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arch = ((96,11,4,0,2,3),(256,5,1,2,2,3),(384,3,1,1,2,3),(10,3,1,1,2,3))\n",
    "model = Nin(arch)\n",
    "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
    "trainer.fit(model, data)\n",
    "X,y = next(iter(data.get_dataloader(False)))\n",
    "X = X.to('cuda')\n",
    "y = y.to('cuda')\n",
    "y_hat = model(X) \n",
    "print(f'acc: {model.accuracy(y_hat,y).item():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3048f1be-7b68-427a-b910-a20d6e22ef35",
   "metadata": {},
   "source": [
    "# 3. What happens if you replace the global average pooling by a fully connected layer (speed, accuracy, number of parameters)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6705bb-38cc-425c-bc41-d6fb62f42162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNin(d2l.Classifier):\n",
    "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        layers = []\n",
    "        for i in range(len(arch)-1):\n",
    "            layers.append(nin_block(*arch[i]))\n",
    "            layers.append(nn.MaxPool2d(3, stride=2))\n",
    "        layers.append(nn.Dropout(0.5))\n",
    "        layers.append(nin_block(*arch[-1]))\n",
    "        layers.append(nn.Flatten())\n",
    "        layers.append(nn.LazyLinear(num_classes))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.net.apply(d2l.init_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d951a1-f0e4-4069-a11c-4075a3be3fe7",
   "metadata": {},
   "source": [
    "# 4. Calculate the resource usage for NiN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f9c0d2-05c4-4e33-adad-9cd567408607",
   "metadata": {},
   "source": [
    "## 4.1 What is the number of parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51d14dda-da4e-4b90-949b-d714fbdaaa4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 2015398\n"
     ]
    }
   ],
   "source": [
    "arch = ((96,11,4,0,2),(256,5,1,2,2),(384,3,1,1,2),(10,3,1,1,2))\n",
    "model = Nin(arch)\n",
    "X = torch.randn(1,3, 224, 224)\n",
    "_ = model(X)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca4f6d1-eca1-44c5-8f5b-760351ae39e0",
   "metadata": {},
   "source": [
    "## 4.2 What is the amount of computation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6757f550-0806-411f-8ca1-3a05957a5e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "Total FLOPs: 830042124.0\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "flops, params = profile(model, inputs=(X,))\n",
    "print(\"Total FLOPs:\", flops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad13106-f5bd-418f-b4aa-2c467decee8e",
   "metadata": {},
   "source": [
    "## 4.3 What is the amount of memory needed during training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0650fd-1ee0-45af-85f5-11c4beecd5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd3ba416-6d59-4b7e-a51c-a3dd01ea660a",
   "metadata": {},
   "source": [
    "## 4.4 What is the amount of memory needed during prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61536c7-4ef5-4442-99fa-b58d37309fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8e30da1-d8b8-454d-beec-3837afbe7a38",
   "metadata": {},
   "source": [
    "# 5. What are possible problems with reducing the $384\\times5\\times5$ representation to a $10\\times5\\times5$ representation in one step?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97824f2b-28aa-4a42-9f16-00d294825b49",
   "metadata": {},
   "source": [
    "# 6. Use the structural design decisions in VGG that led to VGG-11, VGG-16, and VGG-19 to design a family of NiN-like networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a822de-5207-4406-85ca-881d06a6268e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd7c7449-eb4a-4621-b700-4f946622568c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17aba178-95c3-409d-9bab-d153c0559c0c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb88fb99-c73c-4e09-b585-d5498f972fbb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l]",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
