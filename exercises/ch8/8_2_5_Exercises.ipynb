{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b524c235-1ea4-4031-90dc-1e72e852a834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import warnings\n",
    "sys.path.append('/home/jovyan/work/d2l_solutions/notebooks/exercises/d2l_utils/')\n",
    "import d2l\n",
    "from torchsummary import summary\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def vgg_block(num_convs, out_channels):\n",
    "    layers = []\n",
    "    for _ in num_convs:\n",
    "        layers.append(nn.LazyConv2d(out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class VGG(d2l.Classifier):\n",
    "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        conv_blks = []\n",
    "        for (num_convs, out_channels) in arch:\n",
    "            conv_blks.append(vgg_block(num_convs, out_channels))\n",
    "        self.net = nn.Sequential(*conv_blks, nn.Flatten(),\n",
    "                                 nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "                                 nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "                                 nn.LazyLinear(num_classes))\n",
    "        self.net.apply(d2l.init_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa51f9-4f86-4bcb-b942-f0462a00ecfa",
   "metadata": {},
   "source": [
    "# 1. Compared with AlexNet, VGG is much slower in terms of computation, and it also needs more GPU memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aecfbd5-c794-4a04-874c-4a1d19ba6945",
   "metadata": {},
   "source": [
    "## 1.1 Compare the number of parameters needed for AlexNet and VGG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a31b89-32f2-4f31-9483-822fc006ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch=((1, 64), (1, 128), (2, 256), (2, 512), (2, 512)))\n",
    "vgg = VGG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8339c6f8-b3d4-4854-b6d9-ebbacc4e0d97",
   "metadata": {},
   "source": [
    "## 1.2 Compare the number of floating point operations used in the convolutional layers and in the fully connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977382a-582e-46af-a8d9-1f2c5f7b3890",
   "metadata": {},
   "source": [
    "## 1.3 How could you reduce the computational cost created by the fully connected layers?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2431661-4919-42de-ac99-141570e8225c",
   "metadata": {},
   "source": [
    "# 2. When displaying the dimensions associated with the various layers of the network, we only see the information associated with eight blocks (plus some auxiliary transforms), even though the network has 11 layers. Where did the remaining three layers go?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecda17b1-0ac7-46cf-a1fb-cbeb8a6c3453",
   "metadata": {},
   "source": [
    "# 3. Use Table 1 in the VGG paper (Simonyan and Zisserman, 2014) to construct other common models, such as VGG-16 or VGG-19.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a974af28-95ab-48e7-b2d8-49f8d8002488",
   "metadata": {},
   "source": [
    "# 4. Upsampling the resolution in Fashion-MNIST eight-fold from \n",
    " to \n",
    " dimensions is very wasteful. Try modifying the network architecture and resolution conversion, e.g., to 56 or to 84 dimensions for its input instead. Can you do so without reducing the accuracy of the network? Consult the VGG paper (Simonyan and Zisserman, 2014) for ideas on adding more nonlinearities prior to downsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f62d23-6215-4bfe-bbca-cf31f0fb5cbd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l]",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
