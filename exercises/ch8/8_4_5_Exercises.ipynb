{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be0443-f027-4184-9b81-0f6c581b91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import warnings\n",
    "sys.path.append('/home/jovyan/work/d2l_solutions/notebooks/exercises/d2l_utils/')\n",
    "import d2l\n",
    "from torchsummary import summary\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
    "        super().__init__(*kwargs)\n",
    "        self.b1 = nn.Sequential(nn.LazyConv2d(c1, kernel_size=1),\n",
    "                                nn.ReLU())\n",
    "        self.b2 = nn.Sequential(nn.LazyConv2d(c2[0], kernel_size=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.LazyConv2d(c2[1], kernel_size=3, padding=1),\n",
    "                                nn.ReLU())\n",
    "        self.b3 = nn.Sequential(nn.LazyConv2d(c3[0], kernel_size=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.LazyConv2d(c3[1], kernel_size=5, padding=2),\n",
    "                                nn.ReLU())\n",
    "        self.b3 = nn.Sequential(nn.LazyConv2d(c3[0], kernel_size=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.LazyConv2d(c3[1], kernel_size=5, padding=2),\n",
    "                                nn.ReLU())\n",
    "        self.b4 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "                                nn.LazyConv2d(c4, kernel_size=1),\n",
    "                                nn.ReLU())\n",
    "    \n",
    "    def forward(self, X):\n",
    "        o1 = self.b1(x)\n",
    "        o2 = self.b2(x)\n",
    "        o3 = self.b3(x)\n",
    "        o4 = self.b4(x)\n",
    "        return torch.cat((o1,o2,o3,o4),dim=1)\n",
    "    \n",
    "class GoogleNet(d2l.Classifier):\n",
    "    def b1(self):\n",
    "        return nn.Sequential(nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "                             nn.ReLU(),\n",
    "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "    def b2(self):\n",
    "        return nn.Sequential(nn.LazyConv2d(64, kernel_size=1), nn.ReLU(),\n",
    "                             nn.LazyConv2d(192, kernel_size=3, padding=1),\n",
    "                             nn.ReLU(),\n",
    "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    def b3(self):\n",
    "        return nn.Sequential(Inception(64, (96, 128), (16, 32), 32),\n",
    "                             Inception(128, (128, 192), (32, 96), 64),\n",
    "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    def b4(self):\n",
    "        return nn.Sequential(Inception(192, (96, 208), (16, 48), 64),\n",
    "                             Inception(160, (112, 224), (24, 64), 64),\n",
    "                             Inception(128, (128, 256), (24, 64), 64),\n",
    "                             Inception(112, (144, 288), (32, 64), 64),\n",
    "                             Inception(256, (160, 320), (32, 128), 128),\n",
    "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    def b5(self):\n",
    "        return nn.Sequential(Inception(256, (160, 320), (32, 128), 128),\n",
    "                             Inception(384, (192, 384), (48, 128), 64),\n",
    "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    def __init__(self, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be26e2d3-9aeb-4e41-a546-96bbfa1869b5",
   "metadata": {},
   "source": [
    "# 1. GoogLeNet was so successful that it went through a number of iterations, progressively improving speed and accuracy. Try to implement and run some of them. They include the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eff0789-9174-4b64-9130-35e6516b834e",
   "metadata": {},
   "source": [
    "## 1.1 Add a batch normalization layer (Ioffe and Szegedy, 2015), as described later in Section 8.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee4ea7c-dcd7-4b2d-88ba-37cb5fc494df",
   "metadata": {},
   "source": [
    "## 1.2 Make adjustments to the Inception block (width, choice and order of convolutions), as described in Szegedy et al. (2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9466df9-9852-4147-95f2-578ef5395cca",
   "metadata": {},
   "source": [
    "## 1.3 Use label smoothing for model regularization, as described in Szegedy et al. (2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7589f2a1-c976-4d66-9d17-f0ea9e77534d",
   "metadata": {},
   "source": [
    "## 1.4 Make further adjustments to the Inception block by adding residual connection (Szegedy et al., 2017), as described later in Section 8.6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82671ed8-d145-41e4-aaef-9b1f09ad7fe3",
   "metadata": {},
   "source": [
    "# 2. What is the minimum image size needed for GoogLeNet to work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8e0409-cd16-4527-ba22-6e8c2a716540",
   "metadata": {},
   "source": [
    "# 3. Can you design a variant of GoogLeNet that works on Fashion-MNISTâ€™s native resolution of $28\\times28$ pixels? How would you need to change the stem, the body, and the head of the network, if anything at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2f73d0-d4bf-4649-8722-23546cc586db",
   "metadata": {},
   "source": [
    "# 4. Compare the model parameter sizes of AlexNet, VGG, NiN, and GoogLeNet. How do the latter two network architectures significantly reduce the model parameter size?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf0ed17-c32c-4248-9808-16a4ac04c483",
   "metadata": {},
   "source": [
    "# 5. Compare the amount of computation needed in GoogLeNet and AlexNet. How does this affect the design of an accelerator chip, e.g., in terms of memory size, memory bandwidth, cache size, the amount of computation, and the benefit of specialized operations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ff0e72-1f9d-4a53-9d10-9112a6421d6e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8a5429d-d7a0-4866-a013-653d2ff69a05",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l]",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
