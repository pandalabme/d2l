{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2ba8f2-1739-4056-a928-df58282076b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to markdown 7_5_5_Exercises.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25305ff5-77d3-47fe-805d-e92e63e3ee83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/d2l_solutions/notebooks/exercises/d2l_utils/d2l.py:128: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(self, 'net'), 'Neural network is defined'\n",
      "/home/jovyan/work/d2l_solutions/notebooks/exercises/d2l_utils/d2l.py:132: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(self, 'trainer'), 'trainer is not inited'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import warnings\n",
    "sys.path.append('/home/jovyan/work/d2l_solutions/notebooks/exercises/d2l_utils/')\n",
    "import d2l\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class Alexnet(d2l.Classifier):\n",
    "    def __init__(self,lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(nn.LazyConv2d(96, kernel_size=11, stride=4, padding=1),\n",
    "                                 nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                                 nn.LazyConv2d(256, kernel_size=5, padding=2),\n",
    "                                 nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                                 nn.LazyConv2d(384, kernel_size=3, padding=1),nn.ReLU(),\n",
    "                                 nn.LazyConv2d(384, kernel_size=3, padding=1),nn.ReLU(),\n",
    "                                 nn.LazyConv2d(256, kernel_size=3, padding=1),nn.ReLU(),\n",
    "                                 nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(),\n",
    "                                 nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "                                 nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "                                 nn.LazyLinear(num_classes)\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908c2c9-9fdb-40f5-9df9-211a8e1c15dd",
   "metadata": {},
   "source": [
    "# 1. Following up on the discussion above, analyze the computational properties of AlexNet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b9a42a-90da-4c0d-a314-6a8b112f730c",
   "metadata": {},
   "source": [
    "## 1.1 Compute the memory footprint for convolutions and fully connected layers, respectively. Which one dominates?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9315196-9107-454f-b0bd-bec6e7e7c089",
   "metadata": {},
   "source": [
    "Fomula of the number of parameters of convolutions is $\\sum^{layers}(c_i*c_o*k_h*k_w+c_o)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d742699-0ff7-488b-952c-90d59898f4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3747200"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*96*11*11+96+96*256*5*5+256+256*384*3*3+384+384*384*3*3+384+384*256*3*3+256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c9f498-552b-461a-9b96-afc954bbc68e",
   "metadata": {},
   "source": [
    "Fomula of the number of parameters of fully connected is $\\sum^{layers}(x_i*x_o+x_o)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d1c3d49-3031-4941-9ccb-2b3a7a2c4fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43040778"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "80*80*4096+4096+4096*4096+4096+4096*10+10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b70c015-82c6-407a-a99c-266fbdd452eb",
   "metadata": {},
   "source": [
    "The **fully connected layers** dominates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "845095a8-e19a-4782-9c17-47d9c1ae37cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv': 3747200, 'lr': 43040778}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Alexnet()\n",
    "X = torch.randn(1,3, 224, 224)\n",
    "_ = model(X)\n",
    "params = {'conv':0, 'lr':0}\n",
    "for idx, module in enumerate(model.net):\n",
    "    if type(module) not in (nn.Linear,nn.Conv2d):\n",
    "        continue\n",
    "    num = sum(p.numel() for p in module.parameters())\n",
    "    # print(f\"Module {idx + 1}: {num} parameters type:{type(module)}\")\n",
    "    if type(module) == nn.Conv2d:\n",
    "        params['conv'] += num\n",
    "       \n",
    "    else:\n",
    "        params['lr'] += num\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6057efe5-b929-4358-8a15-b1ad19eb316c",
   "metadata": {},
   "source": [
    "## 1.2 Calculate the computational cost for the convolutions and the fully connected layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27390c9f-97fc-46af-9a62-7ccdaa3809ac",
   "metadata": {},
   "source": [
    "Fomula of the computational cost for convolutions is $\\sum^{layers}(c_i*c_o*k_h*k_w*h_o*w_o)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6843479-d402-4d15-8267-a2d8bb2f57f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(1,3, 224, 224)\n",
    "_ = model(X)\n",
    "params = {'conv':0, 'lr':0}\n",
    "for idx, module in enumerate(model.net):\n",
    "    if type(module) not in (nn.Linear,nn.Conv2d):\n",
    "        continue\n",
    "    num = sum(p.numel() for p in module.parameters())\n",
    "    # print(f\"Module {idx + 1}: {num} parameters type:{type(module)}\")\n",
    "    if type(module) == nn.Conv2d:\n",
    "        params['conv'] += num\n",
    "       \n",
    "    else:\n",
    "        params['lr'] += num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466538b8-0361-4207-8b78-8c24086db3cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b2be978-176c-49b1-a24a-4925f55984ea",
   "metadata": {},
   "source": [
    "## 1.3 How does the memory (read and write bandwidth, latency, size) affect computation? Is there any difference in its effects for training and inference?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0817e088-7115-4b37-8869-2dee9a3ce75b",
   "metadata": {},
   "source": [
    "# 2. You are a chip designer and need to trade off computation and memory bandwidth. For example, a faster chip requires more power and possibly a larger chip area. More memory bandwidth requires more pins and control logic, thus also more area. How do you optimize?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fd2c24-fafe-40dd-ab27-4eb260fbef14",
   "metadata": {},
   "source": [
    "# 3. Why do engineers no longer report performance benchmarks on AlexNet?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be6392-0a50-4e6d-80da-ffb7d9723396",
   "metadata": {},
   "source": [
    "# 4. Try increasing the number of epochs when training AlexNet. Compared with LeNet, how do the results differ? Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5d88c1-21ca-4fb8-b4be-77a21d8d01c3",
   "metadata": {},
   "source": [
    "# 5. AlexNet may be too complex for the Fashion-MNIST dataset, in particular due to the low resolution of the initial images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630a9314-1280-43f5-b350-abfd4763a3e4",
   "metadata": {},
   "source": [
    "## 5.1 Try simplifying the model to make the training faster, while ensuring that the accuracy does not drop significantly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33759102-52db-43e3-8bd1-1801ca3d50ca",
   "metadata": {},
   "source": [
    "## 5.2 Design a better model that works directly on \n",
    " images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1c9e94-673f-4279-8595-ee6ebab6713b",
   "metadata": {},
   "source": [
    "# 6. Modify the batch size, and observe the changes in throughput (images/s), accuracy, and GPU memory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c9dc2c-7118-4f8b-b0cb-b96cb3e76016",
   "metadata": {},
   "source": [
    "# 7. Apply dropout and ReLU to LeNet-5. Does it improve? Can you improve things further by preprocessing to take advantage of the invariances inherent in the images?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40228f09-dd07-4a92-8d0f-fd90e9c26cbd",
   "metadata": {},
   "source": [
    "# 8. Can you make AlexNet overfit? Which feature do you need to remove or change to break training?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5bcec9-b107-45bc-878a-fd8556dc449c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cb700a3-0caf-41fe-b66b-afd4d2dc2cd2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l]",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
