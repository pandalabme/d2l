{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b998ca91-7364-4fcf-a58a-8e45cfe9039e",
   "metadata": {},
   "source": [
    "# 1. Parzen windows density estimates are given by $\\hat{p}(xd)=\\frac{1}{n}\\sum_ik(x,x_i)$. Prove that for binary classification the function $\\hat{p}(x,y=1)-\\hat{p}(x,y=-1)$, as obtained by Parzen windows is equivalent to Nadaraya–Watson classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181f229f-b63a-4a52-bd5a-2de3d9208199",
   "metadata": {},
   "source": [
    "# 2. Implement stochastic gradient descent to learn a good value for kernel widths in Nadaraya–Watson regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66be0844-5755-431f-b1f6-d9a2c048a750",
   "metadata": {},
   "source": [
    "## 2.1 What happens if you just use the above estimates to minimize $(f(x_i)-y_i)^2$ directly? Hint: $y_i$ is part of the terms used to compute $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3665e3f9-8920-49c1-a454-bbfdd0fdf521",
   "metadata": {},
   "source": [
    "## 2.2 Remove $(x_i,y_i)$ from the estimate for $f(x)$ and optimize over the kernel widths. Do you still observe overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f83372-ee5a-440c-81ae-41e5d82a6cbc",
   "metadata": {},
   "source": [
    "# 3. Assume that all $x$ lie on the unit sphere, i.e., all satisfy $$. Can you simplify the \n",
    " term in the exponential? Hint: we will later see that this is very closely related to dot product attention.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6254e17c-9f35-482a-9ccc-f08eeb654b52",
   "metadata": {},
   "source": [
    "# 4. Recall that Mack and Silverman (1982) proved that Nadaraya–Watson estimation is consistent. How quickly should you reduce the scale for the attention mechanism as you get more data? Provide some intuition for your answer. Does it depend on the dimensionality of the data? How?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd400fe2-520b-4790-9e8e-ec2e9ff99cbe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b2efdbc-2575-4278-9ec6-b4d93dbaef52",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17529b1b-ecda-4d7a-a42a-3209aa4609b8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5686c8cd-1534-4e2c-8706-5211e98f1561",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b78e2a45-f7a0-46d6-982e-47941706fd03",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "744c8e38-554b-4690-adc3-82363d7932de",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l]",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
