{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71aab2fe-785a-454b-9d1b-60da814913c3",
   "metadata": {},
   "source": [
    "# 1. If words $w_i$ and $w_j$ co-occur in the same context window, how can we use their distance in the text sequence to redesign the method for calculating the conditional probability $p_{ij}$? Hint: see Section 4.2 of the GloVe paper (Pennington et al., 2014)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e391c8-872a-4574-b0a7-82fb65492632",
   "metadata": {},
   "source": [
    "According to Section 4.2 of the GloVe paperÂ¹, if two words w_i and w_j co-occur in the same context window, we can use their distance d in the text sequence to redesign the method for calculating the conditional probability p_i(j). Specifically, we can assume that p_i(j) is inversely proportional to d, that is, p_i(j) = 1/d. This way, the closer the words are, the higher the conditional probability is, and the farther the words are, the lower the conditional probability is. This matches our intuition, because the closer the words are, the more likely they express related semantic information, and the farther the words are, the more likely they express unrelated semantic information.\n",
    "\n",
    "Using this method, we can write the logarithm of the conditional probability as:\n",
    "\n",
    "$$\n",
    "\\log p_i(j) = \\log \\frac{1}{d} = -\\log d\n",
    "$$\n",
    "\n",
    "Then, we can use this logarithm of the conditional probability as the objective function of the GloVe model, that is:\n",
    "\n",
    "$$\n",
    "J = \\sum_{i,j=1}^V f(x_{ij}) (\\log d + w_i^T \\tilde{w}_j + b_i + \\tilde{b}_j)^2\n",
    "$$\n",
    "\n",
    "where V is the size of the vocabulary, x_{ij} is the co-occurrence count of words w_i and w_j, f is a weighting function, w_i and \\tilde{w}_j are the word vectors of words w_i and w_j, b_i and \\tilde{b}_j are the bias terms of words w_i and w_j.\n",
    "\n",
    "> (1) GloV:https://nlp.stanford.edu/pubs/glove.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cdb0e38-70bb-4a01-9785-c1fd64481916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import warnings\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "sys.path.append('/home/jovyan/work/d2l_solutions/notebooks/exercises/d2l_utils/')\n",
    "import d2l\n",
    "from torchsummary import summary\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['ptb'] = (d2l.DATA_URL + 'ptb.zip',\n",
    "                       '319d85e578af0cdc590547f26231e4e31cdf1e42')\n",
    "#@save\n",
    "class RandomGenerator:\n",
    "    \"\"\"Randomly draw among {1, ..., n} according to n sampling weights.\"\"\"\n",
    "    def __init__(self, sampling_weights,k=10000):\n",
    "        # Exclude\n",
    "        self.population = list(range(1, len(sampling_weights) + 1))\n",
    "        self.sampling_weights = sampling_weights\n",
    "        self.candidates = []\n",
    "        self.i = 0\n",
    "        self.k = k\n",
    "\n",
    "    def draw(self):\n",
    "        if self.i == len(self.candidates):\n",
    "            # Cache `k` random sampling results\n",
    "            self.candidates = random.choices(\n",
    "                self.population, self.sampling_weights, k=self.k)\n",
    "            self.i = 0\n",
    "        self.i += 1\n",
    "        return self.candidates[self.i - 1]\n",
    "    \n",
    "#@save\n",
    "def subsample(sentences, vocab,flag=True):\n",
    "    \"\"\"Subsample high-frequency words.\"\"\"\n",
    "    # Exclude unknown tokens ('<unk>')\n",
    "    sentences = [[token for token in line if vocab[token] != vocab.unk]\n",
    "                 for line in sentences]\n",
    "    counter = collections.Counter([\n",
    "        token for line in sentences for token in line])\n",
    "    num_tokens = sum(counter.values())\n",
    "\n",
    "    # Return True if `token` is kept during subsampling\n",
    "    def keep(token):\n",
    "        return(random.uniform(0, 1) <\n",
    "               math.sqrt(1e-4 / counter[token] * num_tokens))\n",
    "    if flag:\n",
    "        return ([[token for token in line if keep(token)] for line in sentences],\n",
    "            counter)\n",
    "    return (sentences,counter)\n",
    "\n",
    "#@save\n",
    "def get_centers_and_contexts(corpus, max_window_size,X):\n",
    "    \"\"\"Return center words and context words in skip-gram.\"\"\"\n",
    "    centers, contexts = [], []\n",
    "    for line in corpus:\n",
    "        # To form a \"center word--context word\" pair, each sentence needs to\n",
    "        # have at least 2 words\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "        centers += line\n",
    "        for i in range(len(line)):  # Context window centered at `i`\n",
    "            window_size = random.randint(1, max_window_size)\n",
    "            indices = list(range(max(0, i - window_size),\n",
    "                                 min(len(line), i + 1 + window_size)))\n",
    "            # Exclude the center word from the context words\n",
    "            indices.remove(i)\n",
    "            contexts.append([line[idx] for idx in indices])\n",
    "            for idx in indices:\n",
    "                X[line[idx]][line[i]] += 1\n",
    "                X[line[i]][line[idx]] += 1\n",
    "    return centers, contexts\n",
    "\n",
    "#@save\n",
    "def read_ptb():\n",
    "    \"\"\"Load the PTB dataset into a list of text lines.\"\"\"\n",
    "    data_dir = d2l.download_extract('ptb')\n",
    "    # Read the training set\n",
    "    with open(os.path.join(data_dir, 'ptb.train.txt')) as f:\n",
    "        raw_text = f.read()\n",
    "    return [line.split() for line in raw_text.split('\\n')]\n",
    "\n",
    "#@save\n",
    "def get_negatives(all_contexts, vocab, counter, K, k=10000):\n",
    "    \"\"\"Return noise words in negative sampling.\"\"\"\n",
    "    # Sampling weights for words with indices 1, 2, ... (index 0 is the\n",
    "    # excluded unknown token) in the vocabulary\n",
    "    sampling_weights = [counter[vocab.to_tokens(i)]**0.75\n",
    "                        for i in range(1, len(vocab))]\n",
    "    all_negatives, generator = [], RandomGenerator(sampling_weights,k)\n",
    "    for contexts in all_contexts:\n",
    "        negatives = []\n",
    "        while len(negatives) < len(contexts) * K:\n",
    "            neg = generator.draw()\n",
    "            # Noise words cannot be context words\n",
    "            if neg not in contexts:\n",
    "                negatives.append(neg)\n",
    "        all_negatives.append(negatives)\n",
    "    return all_negatives\n",
    "\n",
    "# #@save\n",
    "# def batchify(data):\n",
    "#     \"\"\"Return a minibatch of examples for skip-gram with negative sampling.\"\"\"\n",
    "#     max_len = max(len(c) + len(n) for _, c, n in data)\n",
    "#     centers, contexts_negatives, masks, labels = [], [], [], []\n",
    "#     for center, context, negative in data:\n",
    "#         cur_len = len(context) + len(negative)\n",
    "#         centers += [center]\n",
    "#         contexts_negatives += [context + negative + [0] * (max_len - cur_len)]\n",
    "#         masks += [[1] * cur_len + [0] * (max_len - cur_len)]\n",
    "#         labels += [[1] * len(context) + [0] * (max_len - len(context))]\n",
    "#     return (torch.tensor(centers).reshape((-1, 1)), torch.tensor(\n",
    "#         contexts_negatives), torch.tensor(masks), torch.tensor(labels))\n",
    "\n",
    "def batchify(data):\n",
    "    \"\"\"Return a minibatch of examples for skip-gram with negative sampling.\"\"\"\n",
    "    max_len = max(len(c) + len(n) for _, c, n in data)\n",
    "    centers, contexts,valid_lens = [], [], []\n",
    "    for center, context, negative in data:\n",
    "        cur_len = len(context)\n",
    "        centers += [center]\n",
    "        contexts += [context + [0] * (max_len - cur_len)]\n",
    "        valid_lens += [[cur_len]]\n",
    "    return (torch.tensor(centers).reshape((-1, 1)), torch.tensor(\n",
    "        contexts), torch.tensor(valid_lens))\n",
    "\n",
    "\n",
    "#@save\n",
    "def load_data_ptb(batch_size, max_window_size, num_noise_words, flag=True, k=10000):\n",
    "    \"\"\"Download the PTB dataset and then load it into memory.\"\"\"\n",
    "    # num_workers = d2l.get_dataloader_workers()\n",
    "    sentences = read_ptb()\n",
    "    vocab = d2l.Vocab(sentences, min_freq=10)\n",
    "    subsampled, counter = subsample(sentences, vocab, flag)\n",
    "    corpus = [vocab[line] for line in subsampled]\n",
    "    n = len(vocab)\n",
    "    X = [[0]*n for i in range(n)]\n",
    "    all_centers, all_contexts = get_centers_and_contexts(\n",
    "        corpus, max_window_size,X)\n",
    "    all_negatives = get_negatives(\n",
    "        all_contexts, vocab, counter, num_noise_words, k=k)\n",
    "\n",
    "    class PTBDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, centers, contexts, negatives):\n",
    "            assert len(centers) == len(contexts) == len(negatives)\n",
    "            self.centers = centers\n",
    "            self.contexts = contexts\n",
    "            self.negatives = negatives\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return (self.centers[index], self.contexts[index],\n",
    "                    self.negatives[index])\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.centers)\n",
    "\n",
    "    dataset = PTBDataset(all_centers, all_contexts, all_negatives)\n",
    "\n",
    "    data_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True,\n",
    "                                      collate_fn=batchify)\n",
    "    return data_iter, vocab,X\n",
    "\n",
    "def skip_gram(center, contexts_and_negatives, embed_v, embed_u):\n",
    "    v = embed_v(center)\n",
    "    u = embed_u(contexts_and_negatives)\n",
    "    pred = torch.bmm(v, u.permute(0, 2, 1))\n",
    "    return pred\n",
    "\n",
    "class SigmoidBCELoss(nn.Module):\n",
    "    # Binary cross-entropy loss with masking\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs, target, mask=None):\n",
    "        out = nn.functional.binary_cross_entropy_with_logits(\n",
    "            inputs, target, weight=mask, reduction=\"none\")\n",
    "        return out.mean(dim=1)\n",
    "    \n",
    "def weighting(X,w_i, w_j):\n",
    "    try:\n",
    "        x_ij = X[w_i][w_j]\n",
    "    except Exception:\n",
    "        x_ij = 1\n",
    "\n",
    "    x_max = 100  # 100 fixed in paper\n",
    "    alpha = 0.75\n",
    "\n",
    "    if x_ij < x_max:\n",
    "        result = (x_ij / x_max)**alpha\n",
    "    else:\n",
    "        result = 1\n",
    "\n",
    "    return result\n",
    "\n",
    "def glove_loss(center, context,net,X):\n",
    "    v = net[0](center)\n",
    "    b = net[1](center)\n",
    "    u = net[2](context)\n",
    "    c = net[3](context)\n",
    "    temp = torch.bmm(v, u.permute(0, 2, 1))\n",
    "    x=np.array(X)\n",
    "    e= np.take(x, a * f.shape[1] + b)\n",
    "    return pred\n",
    "\n",
    "def train(net, data_iter, X, lr, num_epochs, device='cpu'):\n",
    "    def init_weights(module):\n",
    "        if type(module) == nn.Embedding:\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "    net.apply(init_weights)\n",
    "    net = net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "                            xlim=[1, num_epochs])\n",
    "    # Sum of normalized losses, no. of normalized losses\n",
    "    metric = d2l.Accumulator(2)\n",
    "    for epoch in range(num_epochs):\n",
    "        timer, num_batches = d2l.Timer(), len(data_iter)\n",
    "        for i, batch in enumerate(data_iter):\n",
    "            optimizer.zero_grad()\n",
    "            center, context, valid_len =[\n",
    "                data.to(device) for data in batch]\n",
    "            pred = skip_gram(center, context_negative, net[0], net[1])\n",
    "            l = (loss(pred.reshape(label.shape).float(), label.float(), mask)\n",
    "                     / mask.sum(axis=1) * mask.shape[1])\n",
    "            l.sum().backward()\n",
    "            optimizer.step()\n",
    "            metric.add(l.sum(), l.numel())\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (metric[0] / metric[1],))\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, '\n",
    "          f'{metric[1] / timer.stop():.1f} tokens/sec on {str(device)}')\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "def get_similar_tokens(query_token, k, embed):\n",
    "    W = embed.weight.data\n",
    "    x = W[vocab[query_token]]\n",
    "    # Compute the cosine similarity. Add 1e-9 for numerical stability\n",
    "    cos = torch.mv(W, x) / torch.sqrt(torch.sum(W * W, dim=1) *\n",
    "                                      torch.sum(x * x) + 1e-9)\n",
    "    topk = torch.topk(cos, k=k+1)[1].cpu().numpy().astype('int32')\n",
    "    for i in topk[1:]:  # Remove the input words\n",
    "        print(f'cosine sim={float(cos[i]):.3f}: {vocab.to_tokens(i)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "07496354-afd9-446b-9953-b2be2b207d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3,  2,  1,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [11,  6,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=np.array(X)\n",
    "e= np.take(f, a * f.shape[1] + b)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b77673b2-e184-4374-a2e3-b88e0321664c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1363],\n",
       "         [1132]]),\n",
       " tensor([[ 598, 6346, 4623, 5628,  271,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [3098, 4237,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "038f6ed6-3664-4ec9-be36-91201984bacd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  6])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[1132][[ 3098, 4237]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93507dc1-fa86-443a-8502-555e8cc75c58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  5]\n",
      " [12 15]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# åå»ºä¸ä¸ª4*4çäºç»´æ°ç»x\n",
    "x = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])\n",
    "# åå»ºä¸ä¸ª2*2çäºç»´æ°ç»tensor1ï¼ä½ä¸ºè¡ç´¢å¼\n",
    "tensor1 = np.array([[0, 1], [2, 3]])\n",
    "# åå»ºä¸ä¸ª2*2çäºç»´æ°ç»tensorï¼ä½ä¸ºåç´¢å¼\n",
    "tensor = np.array([[1, 0], [3, 2]])\n",
    "# ä½¿ç¨np.takeå½æ°ï¼æ ¹æ®ç´¢å¼ä»xä¸­ååºå¯¹åºçåç´ ï¼å¾å°ä¸ä¸ª2*2çäºç»´æ°ç»y\n",
    "y = np.take(x, tensor1 * x.shape[1] + tensor)\n",
    "# æå°yçç»æ\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "973c4093-6ba5-470e-8dad-4f6253399f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [0, 0, 0],\n",
       "        [2, 2, 2]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.tensor([1, 0, 2]) \n",
    "c.unsqueeze(1).repeat(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87403a5d-1800-4b24-96e1-e35bc7364cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1363, 1363, 1363],\n",
       "        [1132, 1132, 1132]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.repeat(1,len(X))[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa1eef81-4af5-41ab-95ae-712bdc8db4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6719, 6719])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.tensor(X)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8a0d4b4-60d5-4b2f-98aa-df80503e992c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1363][0],X[1132][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c00378f-7f6c-40b5-b6e9-b9c25c371b20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [2]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(d,0,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ade07921-0891-4c4a-9fb3-b2c21f870ffe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = center[:2]\n",
    "b = context[:2]\n",
    "d = torch.gather(a, 1, c.unsqueeze(1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be42b628-0d3a-46b0-aad4-bcf832c4f451",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [4],\n",
       "        [9]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) # äºç»´æ°ç»\n",
    "b = torch.tensor([0, 1, 2]) # è¡ç´¢å¼\n",
    "c = torch.tensor([1, 0, 2]) # åç´¢å¼\n",
    "d = torch.gather(a, 1, c.unsqueeze(1)) # æåæ¶éï¼å¾å°tensor([[2], [4], [9]])\n",
    "# e = torch.gather(a, 0, b.unsqueeze(1).repeat(1, 3)) # æè¡æ¶éï¼å¾å°tensor([[1, 2, 3], \n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56467909-ff8a-491b-9d9e-e95045ca0bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 598, 6346, 4623, 5628,  271,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [3098, 4237,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]]),\n",
       " tensor([[1363],\n",
       "         [1132]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,center[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1acfaee-3461-4222-a5d2-51baf879dd55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.6931, 1.0986, 1.3863, 1.6094, 1.7918, 1.9459, 2.0794, 2.1972,\n",
       "         2.3026, 2.3979, 2.4849, 2.5649, 2.6391, 2.7081, 2.7726, 2.8332, 2.8904,\n",
       "         2.9444, 2.9957, 3.0445, 3.0910, 3.1355, 3.1781, 3.2189, 3.2581, 3.2958,\n",
       "         3.3322, 3.3673, 3.4012, 3.4340, 3.4657, 3.4965, 3.5264, 3.5553, 3.5835,\n",
       "         3.6109, 3.6376, 3.6636, 3.6889, 3.7136, 3.7377, 3.7612, 3.7842, 3.8067,\n",
       "         3.8286, 3.8501, 3.8712, 3.8918, 3.9120, 3.9318, 3.9512, 3.9703, 3.9890,\n",
       "         4.0073, 4.0254, 4.0431, 4.0604, 4.0775, 4.0943],\n",
       "        [0.0000, 0.6931, 1.0986, 1.3863, 1.6094, 1.7918, 1.9459, 2.0794, 2.1972,\n",
       "         2.3026, 2.3979, 2.4849, 2.5649, 2.6391, 2.7081, 2.7726, 2.8332, 2.8904,\n",
       "         2.9444, 2.9957, 3.0445, 3.0910, 3.1355, 3.1781, 3.2189, 3.2581, 3.2958,\n",
       "         3.3322, 3.3673, 3.4012, 3.4340, 3.4657, 3.4965, 3.5264, 3.5553, 3.5835,\n",
       "         3.6109, 3.6376, 3.6636, 3.6889, 3.7136, 3.7377, 3.7612, 3.7842, 3.8067,\n",
       "         3.8286, 3.8501, 3.8712, 3.8918, 3.9120, 3.9318, 3.9512, 3.9703, 3.9890,\n",
       "         4.0073, 4.0254, 4.0431, 4.0604, 4.0775, 4.0943]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a=context[:2]\n",
    "b=torch.log(torch.range(1,context.shape[1])).repeat(context.shape[0],1)\n",
    "b[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50cbbea7-c2f1-4615-888b-7fe8762f5674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for center, context,valid_len in data_iter:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4da987c8-f9d4-4339-95c8-e6cdfb25de97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_iter, vocab, X = load_data_ptb(512, 5, 5)\n",
    "# lr, num_epochs = 0.002, 5\n",
    "# embed_size = 100\n",
    "# net = nn.Sequential(nn.Embedding(num_embeddings=len(vocab),\n",
    "#                                  embedding_dim=embed_size),\n",
    "#                     nn.Embedding(num_embeddings=len(vocab),\n",
    "#                                  embedding_dim=embed_size))\n",
    "# train(net, data_iter, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa83cad-7aed-4647-b9b2-a0e63473ed22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[58, 18,  2,  3],\n",
       "       [18, 84,  5,  4],\n",
       "       [ 2,  5,  4,  0],\n",
       "       [ 3,  4,  0,  0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.array(X)\n",
    "a[:4,:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4382f49e-ed0a-4880-bf64-8c2d6fde965f",
   "metadata": {},
   "source": [
    "# 2. For any word, are its center word bias and context word bias mathematically equivalent in GloVe? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a5978a-6ee6-4f95-a13f-a968d01b7b76",
   "metadata": {},
   "source": [
    "According to the GloVe paper, the center word bias and the context word bias of any word are mathematically equivalent in the GloVe model. This is because the objective function of the GloVe model is symmetric with respect to the center word and the context word, and the optimal solution does not depend on the initialization of the word vectors and the bias terms. Therefore, the center word vector and the context word bias of any word can be interchanged without affecting the objective function value. However, in practice, due to different initialization values, the same word may still get different values in these two vectors after training. GloVe sums them up as the output vector."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l]",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
